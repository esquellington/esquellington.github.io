#+STARTUP: indent

Literary programming exercise: test AVX vs SSE vs Scalar code

* Reference
- Run code block with C-c C-c
- Edit code with C-c ' in separate major-mode buffer (indirect, narrow)
- Tangle code with org-babel-tangle (req :tangle attrib in src block)
** org-babel intro https://orgmode.org/worg/org-contrib/babel/intro.html#source-code-blocks-org
** Supported languages https://orgmode.org/worg/org-contrib/babel/languages.html
** Tutorial http://howardism.org/Technical/Emacs/literate-programming-tutorial.html
** Another tutorial: https://caiorss.github.io/Emacs-Elisp-Programming/Org-mode-recipes.html#sec-1-5
** C++ execution commented https://www.cs.unm.edu/~eschulte/data/babel-c-execution.html
* PRELUDE: elisp CUSTOMIZE VAR to avoid repeated confirmation prompt
#+BEGIN_SRC elisp :results silent
  (setq org-confirm-babel-evaluate nil)
#+END_SRC
* C++ TEST-AVX
** CODE
-O3 causes auto-vectorization and float1 is equivalent to simd8
#+name: test-avx
#+BEGIN_SRC C++ :tangle test-avx.cpp :flags -std=c++14 -O3 -march=native
  //See https://orgmode.org/worg/org-contrib/babel/languages/ob-doc-C.html
  #include <stdio.h>
  #include <chrono>
  #include <immintrin.h>
  using namespace std;
  int main()
  {
      const int cNumEntries(1024);
      const int cNumFloats(8*cNumEntries);
      const int cNumIter(100000);
      // Input
      float* vecWeights8( (float*)_mm_malloc( sizeof(float)*cNumFloats, 32 ) );
      float* vecCoords8( (float*)_mm_malloc( sizeof(float)*cNumFloats, 32 ) );
      for( int i=0; i<cNumFloats; ++i ) vecWeights8[i] = float(i+1)/cNumFloats;
      for( int i=0; i<cNumFloats; ++i ) vecCoords8[i] = cNumFloats/float(i+1);
      // Output
      float* vecResults( (float*)_mm_malloc( sizeof(float)*cNumEntries, 32 ) );

      // Tests
      auto s = chrono::system_clock::now();
      float acc_int1(0.0f);
      for( int i=0; i<cNumIter; ++i )
          for( int j=0; j<cNumEntries; ++j )
          {
              int tmp(0);
              for( int k=0; k<8; ++k )
                  tmp += reinterpret_cast<const int*>(vecWeights8)[8*j+k]
                         ,* reinterpret_cast<const int*>(vecCoords8)[8*j+k];
              vecResults[j] = (float)tmp;
              acc_int1 += vecResults[j];
          }
      auto e = chrono::system_clock::now();
      printf("INT1 %d T %1.6f\n", (int)acc_int1, chrono::duration<float>(e-s).count());

      float acc_float1(0.0f);
      s = chrono::system_clock::now();
      for( int i=0; i<cNumIter; ++i )
          for( int j=0; j<cNumEntries; ++j )
          {
              float tmp(0);
              for( int k=0; k<8; ++k )
                  tmp += vecWeights8[8*j+k] * vecCoords8[8*j+k];
              vecResults[j] = tmp;
              acc_float1 += vecResults[j];
          }
      e = chrono::system_clock::now();
      printf("FLOAT1 %f T %1.6f\n", acc_float1, chrono::duration<float>(e-s).count());

      float acc_simd4(0.0f);
      s = chrono::system_clock::now();
      for( int i=0; i<cNumIter; ++i )
          for( int j=0; j<cNumEntries; ++j )
          {
              __m128 simd03 = _mm_mul_ps( _mm_load_ps(vecWeights8+j*8),
                                          _mm_load_ps(vecCoords8+j*8) );
              __m128 simd47 = _mm_mul_ps( _mm_load_ps(vecWeights8+j*8+4),
                                          _mm_load_ps(vecCoords8+j*8+4) );
              //TODO ensure this adds 4 lanes
              vecResults[j] = _mm_hadd_ps( simd03, _mm_hadd_ps( simd03, simd03 ) )[0]
                              + _mm_hadd_ps( simd47, _mm_hadd_ps( simd47, simd47 ) )[0];
              acc_simd4 += vecResults[j];
          }
      e = chrono::system_clock::now();
      printf("SIMD4 %f T %1.6f\n", acc_simd4, chrono::duration<float>(e-s).count());

      float acc_simd8(0.0f);
      s = chrono::system_clock::now();
      for( int i=0; i<cNumIter; ++i )
          for( int j=0; j<cNumEntries; ++j )
          {
              __m256 simd07 = _mm256_mul_ps( _mm256_load_ps(vecWeights8+j*8),
                                             _mm256_load_ps(vecCoords8+j*8) );
              //TODO ensure this adds 8 lanes
              vecResults[j] = _mm256_hadd_ps(simd07,_mm256_hadd_ps(simd07,simd07) )[0]
                              + _mm256_hadd_ps(simd07,_mm256_hadd_ps(simd07,simd07) )[0];
              acc_simd8 += vecResults[j];
          }
      e = chrono::system_clock::now();
      printf("SIMD8 %f T %1.6f\n", acc_simd8, chrono::duration<float>(e-s).count());
      _mm_free( vecWeights8 );
      _mm_free( vecCoords8 );
      _mm_free( vecResults );
      return 0;
  }
#+END_SRC

#+RESULTS: test-avx
| INT1   | -2147483648 | T | 0.346446 |
| FLOAT1 | 134217728.0 | T | 0.385269 |
| SIMD4  |  67108864.0 | T | 0.277574 |
| SIMD8  |  67108864.0 | T | 0.207161 |

** elisp TANGLE to .cpp
#+BEGIN_SRC elisp :results silent
  (format "Calling tangle on test-avx")
  (org-babel-tangle)
#+END_SRC
** shell COMPILE to EXE and ASM
- Ideally, we'd get org-babel to yield intermediate asm and exe, but
  they seem to just be temporaries and not accessible, so we do it
  here explicitly
#+BEGIN_SRC sh :results silent
  echo "Compiling tangled text-avx.cpp"
  g++ -std=c++14 -O3 -march=native test-avx.cpp -o test-avx
  g++ -std=c++14 -O3 -march=native test-avx.cpp -S -o test-avx.S
#+END_SRC
** shell RUN
#+BEGIN_SRC sh
  echo "Running text-avx"
  ./test-avx
#+END_SRC

#+RESULTS:
| Running |    text-avx |   |          |
| INT1    | -2147483648 | T | 0.347879 |
| FLOAT1  | 134217728.0 | T | 0.387705 |
| SIMD4   |  67108864.0 | T | 0.277489 |
| SIMD8   |  67108864.0 | T |  0.20509 |

** TODO gnuplot PLOT RESULTS
- Use C-c C-x C-v to display inline image

*** Plot function
#+BEGIN_SRC gnuplot :file function.png
  plot sin(x)
#+END_SRC

#+RESULTS:
[[file:function.png]]
*** Plot table
#+tblname: data-table
| x | y1 | y2 |
|---+----+----|
| 0 |  0 |  0 |
| 1 |  1 |  1 |
| 2 |  4 |  8 |
| 3 |  9 | 27 |

#+BEGIN_SRC gnuplot :var data=data-table :file table.png
  plot data u 1:2 with lines, \
       data u 1:3 with lines
#+END_SRC

#+RESULTS:
[[file:table.png]]

* C++ TEST-AVX-GATHER
** CODE
-O3 causes auto-vectorization and float1 is equivalent to simd8
#+name: test-avx-gather
#+BEGIN_SRC C++ :tangle test-avx-gather.cpp :flags -std=c++14 -O3 -march=native
  //See https://orgmode.org/worg/org-contrib/babel/languages/ob-doc-C.html
  #include <stdio.h>
  #include <chrono>
  #include <immintrin.h>
  using namespace std;
  // Computes same weighted sum as TEST-AVX, but on indexed coords
  int main()
  {
      const int cNumEntries(1024);
      const int cNumFloats(8*cNumEntries);
      const int cNumIter(100000);
      // Input
      float* vecCoords8( (float*)_mm_malloc( sizeof(float)*cNumFloats, 32 ) );
      float* vecWeights8( (float*)_mm_malloc( sizeof(float)*cNumFloats, 32 ) );
      int* vecIndices8( (int*)_mm_malloc( sizeof(float)*cNumFloats, 32 ) );
      for( int i=0; i<cNumFloats; ++i ) vecCoords8[i] = cNumFloats/float(i+1);
      for( int i=0; i<cNumFloats; ++i ) vecWeights8[i] = float(i+1)/cNumFloats;
      for( int i=0; i<cNumFloats; ++i ) vecIndices8[i] = cNumFloats - i - 1;
      // Output
      float* vecResults8( (float*)_mm_malloc( sizeof(float)*cNumFloats, 32 ) );
      // Timers
      auto s = chrono::system_clock::now();
      auto e = chrono::system_clock::now();
      // Tests
      s = chrono::system_clock::now();
      for( int i=0; i<cNumIter; ++i )
          for( int j=0; j<cNumEntries; ++j )
              for( int k=0; k<8; ++k )
                  vecResults8[8*j+k] = vecWeights8[8*j+k] * vecCoords8[ vecIndices8[8*j+k] ];
      e = chrono::system_clock::now();
      float acc_float1(0.0f);
      for( int i=0; i<cNumFloats; ++i ) acc_float1 += vecResults8[i];
      printf("FLOAT1 %f T %1.6f\n", acc_float1, chrono::duration<float>(e-s).count());

      s = chrono::system_clock::now();
      for( int i=0; i<cNumIter; ++i )
          for( int j=0; j<cNumEntries; ++j )
          {
              // AVX2 aligned load
              __m128i indices03 = _mm_load_si128( (const __m128i*)(vecIndices8+j*8) );
              __m128i indices47 = _mm_load_si128( (const __m128i*)(vecIndices8+j*8+4) );
              __m128 gather03 = _mm_i32gather_ps( vecCoords8, indices03, 4 );
              __m128 gather47 = _mm_i32gather_ps( vecCoords8, indices47, 4 );
              __m128 simd03 = _mm_mul_ps( _mm_load_ps(vecWeights8+j*8), gather03 );
              __m128 simd47 = _mm_mul_ps( _mm_load_ps(vecWeights8+j*8+4), gather47 );
              _mm_store_ps( vecResults8+j*8, simd03 );
              _mm_store_ps( vecResults8+j*8+4, simd47 );
          }
      e = chrono::system_clock::now();
      float acc_simd4(0.0f);
      for( int i=0; i<cNumFloats; ++i ) acc_simd4 += vecResults8[i];
      printf("SIMD4 %f T %1.6f\n", acc_simd4, chrono::duration<float>(e-s).count());

      s = chrono::system_clock::now();
      for( int i=0; i<cNumIter; ++i )
          for( int j=0; j<cNumEntries; ++j )
          {
              // AVX2 aligned load
              //TODO TRY MULTIPLE GATHERS in seq to fake getting consecutive x,y,z
              __m256i indices07 = _mm256_load_si256( (const __m256i*)(vecIndices8+j*8) );
              __m256 gather07 = _mm256_i32gather_ps( vecCoords8, indices07, 4 );
              __m256 simd07 = _mm256_mul_ps( _mm256_load_ps(vecWeights8+j*8), gather07 );
              _mm256_store_ps( vecResults8+j*8, simd07 );
          }
      e = chrono::system_clock::now();
      float acc_simd8(0.0f);
      for( int i=0; i<cNumFloats; ++i ) acc_simd8 += vecResults8[i];
      printf("SIMD8 %f T %1.6f\n", acc_simd8, chrono::duration<float>(e-s).count());

      _mm_free( vecCoords8 );
      _mm_free( vecWeights8 );
      _mm_free( vecIndices8 );
      _mm_free( vecResults8 );
      return 0;
  }
#+END_SRC

#+RESULTS: test-avx-gather
| FLOAT1 | 70364.03125 | T | 0.830171 |
| SIMD4  | 70364.03125 | T | 1.142072 |
| SIMD8  | 70364.03125 | T | 0.873745 |

** elisp TANGLE to .cpp
#+BEGIN_SRC elisp :results silent
  (format "Calling tangle on test-avx-gather")
  (org-babel-tangle)
#+END_SRC
** shell COMPILE to EXE and ASM
- Ideally, we'd get org-babel to yield intermediate asm and exe, but
  they seem to just be temporaries and not accessible, so we do it
  here explicitly
#+BEGIN_SRC sh :results silent
  echo "Compiling tangled text-avx-gather.cpp"
  g++ -std=c++14 -O3 -march=native test-avx-gather.cpp -o test-avx-gather
  g++ -std=c++14 -O3 -march=native test-avx-gather.cpp -S -o test-avx-gather.S
#+END_SRC
** shell RUN
#+BEGIN_SRC sh
  echo "Running text-avx-gather"
  ./test-avx-gather
#+END_SRC

#+RESULTS:
| Running | text-avx-gather |   |          |
| INT1    |     -2147483648 | T | 0.348499 |
| FLOAT1  |     134217728.0 | T | 0.384117 |
| SIMD4   |      67108864.0 | T | 0.275123 |
| SIMD8   |      67108864.0 | T | 0.203366 |

* C++ TEST-AVX-GATHER-Vec3f
** CODE
o-O3 causes auto-vectorization and float1 is equivalent to simd8
#+name: test-avx-gather-vec3f
#+BEGIN_SRC C++ :tangle test-avx-gather-vec3f.cpp :flags -std=c++14 -O3 -march=native
  //See https://orgmode.org/worg/org-contrib/babel/languages/ob-doc-C.html
  #include <stdio.h>
  #include <chrono>
  #include <immintrin.h>
  using namespace std;

  const int cNumIter(10000);
  const int cNumEntries(1000);
  const int cNumFloats(8*cNumEntries);

  void FLOAT1( float* vecResults8, const float* vecCoords3x8, const float* vecWeights8, const int* vecIndices8 )
  {
      auto s = chrono::system_clock::now();
      for( int i=0; i<cNumIter; ++i )
          for( int j=0; j<cNumEntries; ++j )
              for( int k=0; k<8; ++k )
              {
                  const int base_idx( 3*vecIndices8[8*j+k] );
                  const float w( vecWeights8[8*j+k] );
                  vecResults8[8*j+k]  = w * vecCoords3x8[ base_idx + 0 ];
                  vecResults8[8*j+k] += w * vecCoords3x8[ base_idx + 1 ];
                  vecResults8[8*j+k] += w * vecCoords3x8[ base_idx + 2 ];
              }
      auto e = chrono::system_clock::now();
      float acc_float1(0.0f);
      for( int i=0; i<cNumFloats; ++i ) acc_float1 += vecResults8[i];
      printf("FLOAT1 %f T %1.6f\n", acc_float1, chrono::duration<float>(e-s).count());
  }

  void SIMD8( float* vecResults8, const float* vecCoords3x8, const float* vecWeights8, const int* vecIndices8 )
  {
      auto s = chrono::system_clock::now();
      const __m256i one07( _mm256_set1_epi32(1) );
      const __m256i three07( _mm256_set1_epi32(3) );
      for( int i=0; i<cNumIter; ++i )
          for( int j=0; j<cNumEntries; ++j )
          {
              // Load base indices and multiply by stride 3
              // IMPORTANT mullo does C07=A07*B07, regular mul just multiplies 0..3!!
              __m256i base07 = _mm256_load_si256( (const __m256i*)(vecIndices8+j*8) );
              base07 = _mm256_mullo_epi32( base07, three07 );
              // Get (X,Y,Z) by incrementing indices
              __m256 x07 = _mm256_i32gather_ps( vecCoords3x8, base07, 4 );
              __m256i indices07 = _mm256_add_epi32( base07, one07 );
              __m256 y07 = _mm256_i32gather_ps( vecCoords3x8, indices07, 4 );
              indices07 = _mm256_add_epi32( indices07, one07 );
              __m256 z07 = _mm256_i32gather_ps( vecCoords3x8, indices07, 4 );
              // Get weights
              __m256 w07 = _mm256_load_ps(vecWeights8+j*8);
              // w*(X,Y,Z)
              __m256 wx07 = _mm256_mul_ps( w07 , x07 );
              __m256 wy07 = _mm256_mul_ps( w07, y07 );
              __m256 wz07 = _mm256_mul_ps( w07, z07 );
              // Store wX+wY+wZ
              _mm256_store_ps( vecResults8+j*8,
                               _mm256_add_ps( wx07, _mm256_add_ps( wy07, wz07 ) ) );
          }
      auto e = chrono::system_clock::now();
      float acc_simd8(0.0f);
      for( int i=0; i<cNumFloats; ++i ) acc_simd8 += vecResults8[i];
      printf("SIMD8 %f T %1.6f\n", acc_simd8, chrono::duration<float>(e-s).count());

  }

  // Computes same weighted sum as TEST-AVX, but on indexed coords
  int main()
  {
      // Input
      // coords xyz,xyz,...
      float* vecCoords3x8( (float*)_mm_malloc( 3*sizeof(float)*cNumFloats, 32 ) );
      float* vecWeights8( (float*)_mm_malloc( sizeof(float)*cNumFloats, 32 ) );
      int* vecIndices8( (int*)_mm_malloc( sizeof(float)*cNumFloats, 32 ) );
      for( int i=0; i<3*cNumFloats; ++i ) vecCoords3x8[i] = cNumFloats/float(i+1);
      for( int i=0; i<cNumFloats; ++i ) vecWeights8[i] = float(i+1)/cNumFloats;
      for( int i=0; i<cNumFloats; ++i ) vecIndices8[i] = cNumFloats - i - 1;
      // Output
      float* vecResults8( (float*)_mm_malloc( sizeof(float)*cNumFloats, 32 ) );

      FLOAT1(vecResults8,vecCoords3x8,vecWeights8,vecIndices8);
      SIMD8(vecResults8,vecCoords3x8,vecWeights8,vecIndices8);

      _mm_free( vecCoords3x8 );
      _mm_free( vecWeights8 );
      _mm_free( vecIndices8 );
      _mm_free( vecResults8 );
      return 0;
  }
#+END_SRC

#+RESULTS: test-avx-gather-vec3f
| FLOAT1 | 77311.179688 | T | 0.123735 |
| SIMD8  | 77311.179688 | T | 0.147603 |

** elisp TANGLE to .cpp
#+BEGIN_SRC elisp :results silent
  (format "Calling tangle on test-avx-gather-vec3f")
  (org-babel-tangle)
#+END_SRC
** shell COMPILE to EXE and ASM
- Ideally, we'd get org-babel to yield intermediate asm and exe, but
  they seem to just be temporaries and not accessible, so we do it
  here explicitly
#+BEGIN_SRC sh :results silent
  echo "Compiling tangled text-avx-gather-vec3f.cpp"
  g++ -std=c++14 -O3 -march=native test-avx-gather-vec3f.cpp -o test-avx-gather-vec3f
  g++ -std=c++14 -O3 -march=native test-avx-gather-vec3f.cpp -S -o test-avx-gather-vec3f.S
#+END_SRC
** shell RUN
#+BEGIN_SRC sh
  echo "Running text-avx-gather-vec3f"
  ./test-avx-gather-vec3f
#+END_SRC
** Analysis
- At -O3 -mavx2, FLOAT1 uses 128b instructions (xmm) and runs 10%
  faster than SIMD8.
- Looking at the assembly, FLOAT1 seems to unroll the loop heavily (8
  iter?), while SIMD8 is almost a direct translation of the intrinsic code.
